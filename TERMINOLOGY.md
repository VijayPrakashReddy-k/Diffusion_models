## ðŸ“Œ 1. Downstream Task:

In machine learning, a downstream task refers to a task that is performed using the output of a previous task or model as input. The output of the previous task is usually considered as a pre-processing step that helps to extract useful features or representations that can be used for the downstream task.

For example, in image recognition, a pre-trained model can be used to extract features from images, and these features can then be used as input to a downstream task, such as object detection or image segmentation. In this scenario, the pre-trained model is the upstream task, and the downstream task is the task that uses the features extracted by the pre-trained model.

Downstream tasks are often used in transfer learning, where a model is trained on a source task and then used for a target task that is related to the source task. The pre-trained model on the source task is used as a feature extractor or initialization for the target task, and the downstream task is performed on the output of the pre-trained model.

The use of downstream tasks can help to improve the performance of machine learning models by leveraging the knowledge learned from a previous task. It can also help to reduce the amount of training data needed for the downstream task and accelerate the training process.
